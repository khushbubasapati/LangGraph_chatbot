# Chatbot Application using LangGraph, LangChain, LangSmith & Hugging Face

A production-ready chatbot built using **LangGraph**, **LangChain**, **LangSmith**, **Hugging Face models**, and a **Streamlit UI**. The system supports **tool use**, including a custom **RAG tool**, real-time **streaming responses**, and persistent memory using **SQLiteSaver**.

---

## ğŸš€ Features

### ğŸ”¹ LangGraph Workflow

* Modular graph-based architecture for better control over agent flow.
* Custom nodes for LLM interaction, RAG, memory, and tool execution.

### ğŸ”¹ LangChain Integration

* Chains and tools integrated seamlessly.
* SQLiteSaver used for storing conversation history and memory.

### ğŸ”¹ Hugging Face Model Support

* Pluggable architecture to use various HF text-generation models.
* Works with both local and API-based models.

### ğŸ”¹ RAG (Retrieval-Augmented Generation)

* Document ingestion and embedding generation.
* Retrieval using vector database for context-aware responses.

### ğŸ”¹ Tools Implementation

Includes a variety of tools:

* RAG tool for knowledge retrieval
* Search tool (DuckDuckGoSearch)
* Calculator tool
* get_stock_price tool

### ğŸ”¹ Real-Time Streaming

* Implemented token-by-token streaming in Streamlit using async callbacks.

### ğŸ”¹ Streamlit UI

* Clean, interactive interface for chatting with the model.
* Displays streaming output.
* Supports session persistence.

### ğŸ”¹ SQLiteSaver Memory

* Stores previous conversation state.
* Allows agent to maintain context between turns.

---

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ app.py                  # Streamlit frontend
â”œâ”€â”€ langgraph_chatbot.py       # LangGraph workflow
â”œâ”€â”€ memory/                 # SQLiteSaver setup
â”œâ”€â”€ data/                   # Documents for RAG
â””â”€â”€ README.md               # Project documentation
```

---

## âš™ï¸ Installation

```bash
pip install -r requirements.txt
```

Make sure you have the necessary Hugging Face tokens/config if required.

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

---

## âš¡ How It Works

### 1. User sends a query from Streamlit.

### 2. Query flows through LangGraph:

* Memory â†’ LLM â†’ Tools â†’ RAG (if needed)
* Uses LangChain wrappers & utilities

### 3. Streaming callback returns tokens to UI.

### 4. SQLiteSaver stores conversation for persistence.

---

## ğŸ“š RAG Pipeline

1. Load documents
2. Generate embeddings
3. Store in vector DB
4. Retrieve top-k docs
5. Inject into LLM context

---

## ğŸ› ï¸ Tools Implemented

* **RAGTool** â€“ retrieves context
* **Search or API tools (optional)**
* **Math/Utility tools**
* **Any custom workflow-specific tools**

---




